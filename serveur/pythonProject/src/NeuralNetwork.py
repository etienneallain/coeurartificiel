import os

import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt

from src.Trainer import Trainer, test_model, test_model_NNs
from src.data import Data
from src.Player import RandomPlayer, NNPlayer
from src.manche import Manche


class CustomDataset(Dataset):
    def __init__(self, data):
        self.inputs = [torch.tensor(item[0]).clone().detach().float() for item in data]
        self.outputs = [torch.tensor(item[1]).clone().detach().float() for item in data]

    def __len__(self):
        return len(self.inputs)

    def __getitem__(self, idx):
        return self.inputs[idx], self.outputs[idx]


class NeuralNetwork(torch.nn.Module):
    def __init__(self, input_size, output_size):
        super(NeuralNetwork, self).__init__()
        self.fc1 = torch.nn.Linear(input_size, 64)
        self.fc2 = torch.nn.Linear(64, 64)
        self.fc3 = torch.nn.Linear(64, output_size)

    def forward(self, x):
        x = torch.nn.functional.relu(self.fc1(x))
        x = torch.nn.functional.relu(self.fc2(x))
        x = self.fc3(x)
        return x


def squared_error_masked(y_true, y_pred, scale_factor=1.0):
    """ Squared error of elements where y_true is not 0 """
    mask = y_true != 0
    err = y_pred - (y_true * scale_factor)
    masked_err = err[mask]
    return torch.sum(masked_err ** 2)


def train_model(model, dataloader, optimizer, num_epochs):
    losses = []
    for epoch in range(num_epochs):
        epoch_losses = []
        for inputs, targets in dataloader:
            outputs = model(inputs)
            loss = squared_error_masked(targets, outputs)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            epoch_losses.append(loss.item())
        epoch_loss = np.mean(epoch_losses)
        losses.append(epoch_loss)
        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {epoch_loss:.4f}')
    return losses


def save_model(model, filepath):
    torch.save(model.state_dict(), filepath)


def load_model(input_size, output_size, filepath):
    model = NeuralNetwork(input_size, output_size)
    model.load_state_dict(torch.load(filepath))
    return model


# if __name__ == '__main__':
#     model = load_model(112, 32, "trained_model_2.pth")
#     model_bad = load_model(112, 32, "trained_model_0.pth")
#     print("Model loaded.")
#     test_model_NNs(model,model_bad,250)
#     print("Test finished.")
if __name__ == '__main__':
    # Initial dataset generated by random players
    dataset = Data()
    dataset = CustomDataset(dataset.generate_random_player_data(200))

    # PARAMETRES #
    input_size = 112
    output_size = 32
    learning_rate = 0.001
    batch_size = 32
    num_epochs = 10
    num_models = 3
    data_points_per_model = [200, 800, 1600]
    model_filepaths = ['trained_model_{}.pth'.format(i) for i in range(num_models)]

    for i in range(num_models):
        print("Training Model", i + 1)

        # Initialize or load the model
        if os.path.exists(model_filepaths[i]):
            model = load_model(input_size, output_size, model_filepaths[i])
            print("Model loaded.")
        else:
            model = NeuralNetwork(input_size, output_size)
            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
            trainer = Trainer(model, dataset, batch_size, learning_rate, num_epochs)
            losses = trainer.train()
            save_model(model, model_filepaths[i])
            print("Model trained and saved.")

        # Generate a new dataset using the current model
        new_dataset = Data()
        new_dataset = CustomDataset(new_dataset.generate_NN_data(data_points_per_model[i], model))

        dataset = new_dataset

